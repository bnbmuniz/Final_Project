{\rtf1\ansi\ansicpg1252\cocoartf2636
\cocoatextscaling0\cocoaplatform0{\fonttbl\f0\fswiss\fcharset0 Helvetica;\f1\fswiss\fcharset0 Helvetica-Bold;\f2\fswiss\fcharset0 Helvetica-Oblique;
\f3\fswiss\fcharset0 ArialMT;\f4\froman\fcharset0 Times-Roman;\f5\fswiss\fcharset0 Arial-ItalicMT;
\f6\fswiss\fcharset0 Arial-BoldMT;}
{\colortbl;\red255\green255\blue255;\red0\green0\blue0;\red231\green231\blue231;\red54\green54\blue54;
\red255\green255\blue255;\red69\green69\blue69;\red81\green147\blue221;\red19\green19\blue29;\red163\green163\blue163;
\red101\green175\blue4;\red13\green17\blue23;\red14\green14\blue14;\red19\green19\blue29;\red251\green2\blue7;
\red24\green25\blue27;\red19\green19\blue29;}
{\*\expandedcolortbl;;\cssrgb\c0\c0\c0;\cssrgb\c92549\c92549\c92549;\cssrgb\c27451\c27451\c27451;
\cssrgb\c100000\c100000\c100000;\cssrgb\c34118\c34118\c34118;\cssrgb\c38431\c65098\c89412;\cssrgb\c9804\c9804\c15294;\cssrgb\c69804\c69804\c69804;
\cssrgb\c46275\c72549\c0;\cssrgb\c5882\c8627\c11765;\cssrgb\c6667\c6667\c6667;\cssrgb\c9804\c9804\c15294;\cssrgb\c100000\c14913\c0;
\cssrgb\c12549\c12941\c14118;\cssrgb\c9804\c9804\c15294\c50196;}
{\*\listtable{\list\listtemplateid1\listhybrid{\listlevel\levelnfc23\levelnfcn23\leveljc0\leveljcn0\levelfollow0\levelstartat1\levelspace360\levelindent0{\*\levelmarker \{disc\}}{\leveltext\leveltemplateid1\'01\uc0\u8226 ;}{\levelnumbers;}\fi-360\li720\lin720 }{\listname ;}\listid1}
{\list\listtemplateid2\listhybrid{\listlevel\levelnfc23\levelnfcn23\leveljc0\leveljcn0\levelfollow0\levelstartat1\levelspace360\levelindent0{\*\levelmarker \{disc\}}{\leveltext\leveltemplateid101\'01\uc0\u8226 ;}{\levelnumbers;}\fi-360\li720\lin720 }{\listname ;}\listid2}}
{\*\listoverridetable{\listoverride\listid1\listoverridecount0\ls1}{\listoverride\listid2\listoverridecount0\ls2}}
\paperw11900\paperh16840\margl1440\margr1440\vieww25400\viewh16000\viewkind0
\pard\tx566\tx1133\tx1700\tx2267\tx2834\tx3401\tx3968\tx4535\tx5102\tx5669\tx6236\tx6803\pardirnatural\partightenfactor0

\f0\fs28 \cf2 Speech Recognition:
\f1\b  \cb3 \expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec4 Library for performing speech recognition, with support for several engines and APIs, online and offline.
\f0\b0 \cb1 \
\kerning1\expnd0\expndtw0 \outl0\strokewidth0 \
\
\pard\pardeftab720\partightenfactor0

\f1\b \cf2 \cb5 \expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec6 Pre-trained models (PTMs) for NLP are\'a0{\field{\*\fldinst{HYPERLINK "https://vitalflux.com/category/deep-learning"}}{\fldrslt \ul \strokec7 deep learning}}\'a0models (such as transformers) which are trained on a large dataset to perform specific NLP tasks. PTMs when trained on the large corpus can learn universal language representations, 
\f0\b0 which can be beneficial for downstream\'a0{\field{\*\fldinst{HYPERLINK "https://vitalflux.com/category/nlp"}}{\fldrslt \ul \strokec7 NLP}}\'a0tasks and can avoid training a new model from scratch.\cb1 \kerning1\expnd0\expndtw0 \outl0\strokewidth0 \
\pard\tx566\tx1133\tx1700\tx2267\tx2834\tx3401\tx3968\tx4535\tx5102\tx5669\tx6236\tx6803\pardirnatural\partightenfactor0
\cf2 \
NLP Model: 
\f1\b A\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec5 bstractive Text Summarization (ATS) is the process of finding the most essential meaning of a text and rewriting them in a summary. The resulting summary is an interpretation of the source.
\f0\b0 \
\
\pard\pardeftab720\partightenfactor0
\cf2 \cb5 \strokec8 CLIP (
\f2\i Contrastive Language\'96Image Pre-training
\f0\i0 ) builds on a large body of work on zero-shot transfer, natural language supervision, and multimodal learning.\
\
\pard\pardeftab720\partightenfactor0
\cf2 \cb1 \strokec9 (\strokec2 CUDA is a parallel computing platform and programming model created by NVIDIA. With more than 20 million downloads to date,\'a0{\field{\*\fldinst{HYPERLINK "https://developer.nvidia.com/cuda-zone"}}{\fldrslt \strokec10 CUDA}}\'a0helps developers speed up their applications by harnessing the power of GPU accelerators // \cf11 \cb5 \strokec11 Docker is an open platform for developing, shipping, and running applications. Docker enables you to separate your applications from your infrastructure so you can deliver software quickly\cf2 \cb1 \strokec2 )\
\
\
\
\

\f1\b \ul WHAT IS CLIP?
\f0\b0 \ulnone \
\
\pard\tx220\tx720\pardeftab720\li720\fi-720\partightenfactor0
\ls1\ilvl0
\f3\fs36 \cf12 \cb5 \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	\uc0\u8226 	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec12 CLIP is a neural network model:
\fs28 \cf2  
\f4\fs36 \cb1 \strokec5 first multimodal (in this case, vision and text) model tackling computer vision
\f3 \cf12 \strokec12 \
\ls1\ilvl0\cb5 \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	\uc0\u8226 	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec12 There are 400,000,000 pictures and their captions that are matched up, and this is the data that is used in training the CLIP model.\cb1 \
\pard\tx220\tx720\pardeftab720\li720\fi-720\partightenfactor0
\ls1\ilvl0
\f5\i \cf12 \cb5 \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	\uc0\u8226 	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec12 "It can predict the most relevant text snippet, given an image."
\f3\i0 \'a0You can input an image into the CLIP model, and it will return for you the likeliest caption or summary of that image.\cb1 \
\ls1\ilvl0
\f5\i \cb5 \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	\uc0\u8226 	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec12 "without directly optimizing for the task, similarly to the zero-shot capabilities of GPT-2 and 3."
\f3\i0 \'a0Most machine learning models learn a specific task. For example, an image classifier trained on classifying dogs and cats is expected to do well on the task we've given it: classifying dogs and cats. We generally would not expect a machine learning model trained on dogs and cats to be very good at detecting raccoons. However, some models -- including CLIP, GPT-2, and GPT-3 -- tend to perform well on tasks they aren't directly trained to do, which is called "zero-shot learning.\
\pard\tx220\tx720\pardeftab720\li720\fi-720\partightenfactor0
\ls1\ilvl0
\f0\fs28 \cf2 \cb1 \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	\uc0\u8226 	}
\f3\fs36 \cf12 \cb5 \expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec12 it combines Computer vision and Natural Language Processing \
\ls1\ilvl0
\f0\fs28 \cf2 \cb1 \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	\uc0\u8226 	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 \
\pard\pardeftab720\partightenfactor0
\cf2 \cb5 \outl0\strokewidth0 \
\
\
\cf14 Diagram\cf2 \
\
\pard\pardeftab720\sa240\partightenfactor0

\f6\b\fs36 \cf12 \cb5 \outl0\strokewidth0 \strokec12 The CLIP model consists of two sub-models called encoders:
\f3\b0 \
\pard\tx220\tx720\pardeftab720\li720\fi-720\partightenfactor0
\ls2\ilvl0\cf12 \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	\uc0\u8226 	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec12 a text encoder that will embed (smash) text into mathematical space.\cb1 \
\ls2\ilvl0\cb5 \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	\uc0\u8226 	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec12 an image encoder that will embed (smash) images into mathematical space.\cb1 \
\pard\pardeftab720\partightenfactor0
\cf12 \cb5 \strokec12 It uses cosine similarity to see the similarity between two series of numbers.\
\
\
\
\
\'97\
\pard\pardeftab720\partightenfactor0

\fs24 \cf15 \cb1 \strokec15 \
\
\

\fs32 \cb5 VQGAN (Vector Quantized Generative Adversarial Network): VQGAN is\'a0
\f6\b a GAN architecture which can be used to learn and generate novel images based on previously seen data
\f3\b0 .
\fs24 \cb1 \
\pard\pardeftab720\partightenfactor0

\fs36 \cf12 \cb5 \strokec12 \

\f0\fs28 \cf2 \cb5 \outl0\strokewidth0 \
\pard\pardeftab720\partightenfactor0
\cf2 HuggingFace: 
\f3\fs32 \cf15 \cb5 \outl0\strokewidth0 \strokec15 It combines Mask Language Model (MLM) and Next Sentence Prediction (NSP). It's a versatile deep learning model that can be used on\'a0
\f6\b classification, Q&A, translation, summarization
\f3\b0 , and so on
\fs24 \cb1 \

\f0\fs28 \cf2 \cb5 \outl0\strokewidth0 \
\cb1 \outl0\strokewidth0 \strokec2 \
\pard\pardeftab720\partightenfactor0
\cf2 \
}